{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to fb @news page\n",
    "def login(driver, account, password): \n",
    "    \n",
    "    # Enter account\n",
    "    driver.find_element_by_xpath(\"//*[@id=\\\"m_login_email\\\"]\").send_keys(account)\n",
    "\n",
    "    # Enter password\n",
    "    driver.find_element_by_xpath(\"//*[@id=\\\"m_login_password\\\"]\").send_keys(password)\n",
    "\n",
    "    # Submit login\n",
    "    driver.find_element_by_xpath(\"//*[@id=\\\"u_0_5\\\"]\").click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Proceed to home page\n",
    "    driver.find_element_by_xpath('//*[@id=\"root\"]/div[1]/div/div/div[3]/div[1]/div/div/a').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "# Get to article comment section\n",
    "def toCommentSection(page_id, driver, article_id):\n",
    "    # Generate url to each article comment section\n",
    "    url_article = 'https://mobile.facebook.com/story.php?story_fbid=' + article_id + '&id=' + page_id + '&fs=5&focus_composer=0&ref=page_internal'\n",
    "    driver.get(url_article)\n",
    "\n",
    "def initCSV(page):\n",
    "    import csv\n",
    "    with open('results/'+page+'_posts.csv', 'w', encoding=\"utf-8\") as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        filewriter.writerow(['article_index', 'headline', 'status', 'has_headline', \n",
    "                             'has_status', 'has_img', 'has_vid', 'num_hashtags', 'hashtag_text', 'likes'])\n",
    "        \n",
    "def appendResults(page, posts):\n",
    "    df = pd.DataFrame(np.array(posts), columns=['article_index', 'headline', 'status', 'has_headline', \n",
    "                                                'has_status', 'has_img', 'has_vid', 'num_hashtags', 'hashtag_text', 'likes'])\n",
    "    \n",
    "    # Append results to existing file\n",
    "    with open('results/'+page+'_posts.csv', 'a', encoding=\"utf-8\") as f:\n",
    "        df.to_csv(f, header=False, index=False)\n",
    "\n",
    "def getStatusLikes(driver, article_index):\n",
    "    headline = ''\n",
    "    status = ''\n",
    "    has_headline = 0\n",
    "    has_vid = 0\n",
    "    has_img = 0\n",
    "    has_status = 0\n",
    "    num_hashtags = 0\n",
    "    hashtag_text = []\n",
    "    likes = '0'\n",
    "    \n",
    "    try: \n",
    "        headline = driver.find_element_by_css_selector(\"span[data-ad-preview=\\\"headline\\\"]\").text\n",
    "        has_headline = 1\n",
    "    except:\n",
    "        headline = ''\n",
    "        try:\n",
    "            driver.find_element_by_css_selector(\"i[data-ad-preview=\\\"video-cover\\\"]\")\n",
    "            has_vid = 1\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            driver.find_element_by_css_selector(\"i[data-sigil=\\\"photo-image\\\"]\")\n",
    "            has_img = 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    try:\n",
    "        if has_img == 0:\n",
    "            status = driver.find_element_by_css_selector(\"div[data-ad-preview=\\\"message\\\"]\").text\n",
    "            has_status = 1\n",
    "        else:\n",
    "            status = driver.find_element_by_css_selector(\"div[class=\\\"msg\\\"]\").text\n",
    "            has_status = 1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        likes = driver.find_element_by_css_selector(\"div[class=\\\"_1g06\\\"]\").text\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        hashtags = driver.find_elements_by_css_selector(\"span[class=\\\"_5ayu\\\"]\")\n",
    "        num_hashtags = len(hashtags)\n",
    "        hashtag_text = [hashtag.text for hashtag in hashtags]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    hashtag_text = ','.join(hashtag_text) \n",
    "    res_tuple = (article_index, headline, status, has_headline, has_status, has_img, has_vid, num_hashtags, hashtag_text, likes)\n",
    "    return res_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "# Start webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(account)\n",
    "\n",
    "login(driver, password)\n",
    "\n",
    "pages = ['ettoday', 'apple', 'yahoo', 'udn', 'set', 'ltn']\n",
    "for page in pages:\n",
    "    posts = []\n",
    "    initCSV(page)\n",
    "    article_ids = pd.read_csv('/Users/Shayne/jupyter/web-scraping/fb-data/parallelise-all/results-1000-win-fixed/'+page+'_ids.csv', header=None)[0]\n",
    "    page_ids = pd.read_csv('page_ids.csv', header=0, index_col=0, dtype=str)\n",
    "    page_id = page_ids.loc[page].get('page_id')\n",
    "    to_redo = pd.read_csv('redo_index_'+page+'.csv', header=None, index_col=0)[1]\n",
    "    for article_index in to_redo:\n",
    "        article_id = article_ids[article_index]\n",
    "        toCommentSection(page_id, driver, article_id)\n",
    "        posts.append(getStatusLikes(driver, article_index))\n",
    "    appendResults(page, posts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
